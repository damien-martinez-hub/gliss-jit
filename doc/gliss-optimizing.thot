====== Optimizing ======

In this section you will learn how to use several optimisation options.
You can can increase dramatically the simulator speed so pay attention !

===== Simulator's options ===== 

==== profiling ====

When running your simulation with the GLISS librairie through the generated main,
you can activate option :
<code>
-p or -profile=<path_name>
</code>
This option produce a profiling file which contains statistics about instructions number of calls.
Here is the head file format :
<code>
profiling statistics generated by GLISS2 for :
PROC_NAME
| instruction name | instruction identifier (cf. module id.h) | call count |
</code>
The rest of the file would be a list sort by descending number of instruction's calls.
For instance :
<code>
PPC_LWZ_RD_D_LP_RD_RP_ 1 1066162
PPC_OR_RD_RD_RD 2 533975
PPC_STW_RD_D_LP_RD_RP_ 3 414441
PPC_RLWINM_RD_RD_D_D_D 4 364428
// And so on for the rest of the NML instruction set...
</code>

If -p option is to be used, the simulator seek for an existing profiling file
and add new statistics to the old one. If the file doesn't exists it will be created.
You can also specify the profiling file path with '-profile=path'.
This way it is easy to produce a profiling file for an entire set of benches

N.B : This option is not an optimisation itself of course.
but the profiling file will be usefull for what's coming (-p and -PJ options down this section).
He can also help see which instruction deserved more optimisation inside the NML.
Bad NML implementation leads to bad performance, it is something to keep in mind. 

==== statistics ====

Default simulator's main provide two option statistics options in order to guide you in your quest of speed :

<code>
-s or stat
-more-stats
</code>

'-s' display the time of the simulation and the speed in Mips.
Measure is taken with the function 'rusage' (see linux man pages).
Speed and time are computed with the process user time.

-more-stats display the process system time thanks to rusage.
It also display speed and time with the function 'getgettimeofday' (see linux man pages).

==== full speed simulation ====

Through api.h GLISS provides severals methods to simulate a programm.
<code>
void gliss_run_sim(gliss_sim_t *sim);
void gliss_step(gliss_sim_t *sim);
</code>

It's good to know that 'gliss_run_sim' is way faster than 'gliss_step'.
when running the simulation through the default main,
you can simulate with 'gliss_run_sim' by activating options :
<code>
-f or -fast 
</code>

===== GEP's options =====

When generating a new simulator with GEP,
you can improve performances by using the right modules and options 

==== Faster modules ====

Here is a list of different decoding modules sort by order of speed :

   * 'decode32' standard module (slowest speed)
   * 'decode32_inf_cache' Every decoded instructions are cached (use this module at your own risk memory could severly bloat !) 
   * 'decode32_fixed_cache' Every instructions are cached erasing the oldest inserted instruction 
   * 'decode32_lru_cache' Every instructions are cached erasing the oldest used instruction    
   * 'decode32_trace' Provide a method to decode an entire block of instruction and thus accelerate the simulation by reducing the calls to decode    
   * 'decode32_dtrace' Identical as the previous module but size of decoded block is dynamic. 
      blocks are decoded up to the next instruction branch it guaranties a consitent execution when executing an entire block without any further check.
      WARNING : this module must be used with the option '-gen-with-trace' which indicates to GEP that NML has been consistently written with attribute 'set_attr_branch = 1'.
     'set_attr_branch = 1' declared an instruction as a branch instruction in order to correctly build a block of instruction (see NML's, section about it). 
      If you forget to tag a single instruction branch with this attribute, and at the same time you use this module GEP won't see the error and your simulation will be inconsistent !
        
Call GEP with :
<code>
-m decode:<MODULE_NAME>
</code>
In order to load the desired decode module

Two memory modules are availables :
   * fast_mem.c standard memory module with a two level depth hashtable.
   * vfast_mem.c faster module with a one level hashtable, and a better endianness handling 
     (It does not byte swap memory at each memory acces when endianness differs from NML to host machine)
Call GEP with :
<code>
-m mem:<MODULE_NAME>
</code>
In order to load the desired decode module

==== Generation options ==== 


=== Minor option ===
Here two option which could possibly accelerate the simulation :

<code>
-on GLISS_INSTR_FAST_STRUCT // Modifies the way an instruction is represented in GLISS
-on GLISS_NO_MALLOC         // Pre-allocated instructions objects at init time 
                            // instead of doing so dynamically at decode time 
</code>

=== Profiling ===

In order to generate a profiled simulator for a set of benches you can use two options :

<code>
-p <profile_path>
-PJ <nb_instructions> // Can be activated if '-p <profile_path>' is activated
</code>

The first option tells GEP where is the profile file in order to generate profiled C code for the simulator.
It basically sort function by order use considering the profile file.
It is a mandatory option for the nest one : <-PJ nb_instructions>.

PJ stands for profiled jump. 
One big bottleneck of a simulator are the jumps made to the differents instructions handlers (which simulate the instructions).
Most of the time handler's function are stored into a table and executed through the table.
<code>
handler_table[instruction_identifier](operand0, operand1 ...)
</code>
It is a costly operation.

'-PJ <n>' option inline 'n' instruction's handler code into a switch
<code>
switch(instruction_identifier)
case 0: // inline handler's code 
case 1: // ...
// 'n' times
default: handler_table[instruction_identifier](operand0, operand1 ...)
</code>

Of course the 'n' inlined instructions are sorted with the profiling file.
Most of the time 15 is a good value to improve performance. 
But we recommand to find it by yourself it is indeed architecture dependent.

Another trick to win sompe extra MIPS is to compile with gcc option -fno-jump-table.
But the optimale value for 'n' will be usually greater. 
Here again only experiment can guide you.

=== Parse branch attribute ===

By default GLISS ignore the attribute 'set_attr_branch = 1' you will have to specify by activating the GEP option :
<code>
-gen-with-trace
</code>

By doing so you tell GLISS to use branch attribute for optimisation, 
a different decode table will be generated and the use of decoding module 'decode32_dtrace' will be mandatory (see description of this module).

Last warning about this option : you do not want to forget to tag an instruction with 'set_attr_branch = 1' because GEP won't see it.
If you do so, your simulator will simulate inconsistent programm and most likly craches with an 'unknow instruction at addr xxxxxxx'.
Hopefully such an error won't pass cosimulation with validator either.







